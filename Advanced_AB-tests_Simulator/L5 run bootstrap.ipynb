{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Задача 2. Реализация метода оценки эксперимента с помощью bootstrap\n",
    "  \n",
    "\n",
    "Реализуйте функцию для оценки эксперимента с помощью бутстрепа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доработайте метод _run_bootstrap класса ExperimentsService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class Design(BaseModel):\n",
    "    \"\"\"Дата-класс с описание параметров эксперимента.\n",
    "    \n",
    "    statistical_test - тип статтеста. ['ttest', 'bootstrap']\n",
    "    effect - размер эффекта в процентах\n",
    "    alpha - уровень значимости\n",
    "    beta - допустимая вероятность ошибки II рода\n",
    "    bootstrap_iter - количество итераций бутстрепа\n",
    "    bootstrap_ci_type - способ построения доверительного интервала. ['normal', 'percentile', 'pivotal']\n",
    "    bootstrap_agg_func - метрика эксперимента. ['mean', 'quantile 95']\n",
    "    \"\"\"\n",
    "    statistical_test: str\n",
    "    effect: float\n",
    "    alpha: float = 0.05\n",
    "    beta: float = 0.1\n",
    "    bootstrap_iter: int = 1000\n",
    "    bootstrap_ci_type: str\n",
    "    bootstrap_agg_func: str\n",
    "\n",
    "\n",
    "class ExperimentsService:\n",
    "\n",
    "    def _generate_bootstrap_metrics(self, data_one, data_two, design):\n",
    "        \"\"\"Генерирует значения метрики, полученные с помощью бутстрепа.\n",
    "        \n",
    "        :param data_one, data_two (np.array): значения метрик в группах.\n",
    "        :param design (Design): объект с данными, описывающий параметры эксперимента\n",
    "        :return bootstrap_metrics, pe_metric:\n",
    "            bootstrap_metrics (np.array) - значения статистики теста псчитанное по бутстрепным подвыборкам\n",
    "            pe_metric (float) - значение статистики теста посчитанное по исходным данным\n",
    "        \"\"\"\n",
    "        bootstrap_data_one = np.random.choice(data_one, (len(data_one), design.bootstrap_iter))\n",
    "        bootstrap_data_two = np.random.choice(data_two, (len(data_two), design.bootstrap_iter))\n",
    "        if design.bootstrap_agg_func == 'mean':\n",
    "            bootstrap_metrics = bootstrap_data_two.mean(axis=0) - bootstrap_data_one.mean(axis=0)\n",
    "            pe_metric = data_two.mean() - data_one.mean()\n",
    "            return bootstrap_metrics, pe_metric\n",
    "        elif design.bootstrap_agg_func == 'quantile 95':\n",
    "            bootstrap_metrics = (\n",
    "                np.quantile(bootstrap_data_two, 0.95, axis=0)\n",
    "                - np.quantile(bootstrap_data_one, 0.95, axis=0)\n",
    "            )\n",
    "            pe_metric = np.quantile(data_two, 0.95) - np.quantile(data_one, 0.95)\n",
    "            return bootstrap_metrics, pe_metric\n",
    "        else:\n",
    "            raise ValueError('Неверное значение design.bootstrap_agg_func')\n",
    "\n",
    "    def _run_bootstrap(self, bootstrap_metrics, pe_metric, design):\n",
    "        \"\"\"Строит доверительный интервал и проверяет значимость отличий с помощью бутстрепа.\n",
    "        \n",
    "        :param bootstrap_metrics (np.array): статистика теста, посчитанная на бутстрепных выборках.\n",
    "        :param pe_metric (float): значение статистики теста посчитанное по исходным данным.\n",
    "        :return ci, pvalue:\n",
    "            ci [float, float] - границы доверительного интервала\n",
    "            pvalue (float) - 0 если есть статистически значимые отличия, иначе 1.\n",
    "                Настоящее pvalue для произвольного способа построения доверительного интервала с помощью\n",
    "                бутстрепа вычислить не тривиально. Поэтому мы будем использовать краевые значения 0 и 1.\n",
    "        \"\"\"\n",
    "        # YOUR_CODE_HERE\n",
    "        if design.bootstrap_ci_type == 'normal':\n",
    "\n",
    "            c = stats.norm.ppf(1 - design.alpha / 2)\n",
    "            se = np.std(bootstrap_metrics) # на бутстрепных метриках оцениваем стандартное отклонение\n",
    "            left, right = pe_metric - c * se, pe_metric + c * se # точечная оценка +/- квантиль нормального распределения умноженное на стандартное отклонение\n",
    "            \n",
    "            ci = [left, right]\n",
    "            if left < 0 < right:\n",
    "                pvalue = 1\n",
    "            else:\n",
    "                pvalue = 0\n",
    "            \n",
    "        if design.bootstrap_ci_type == 'percentile':\n",
    "\n",
    "            left, right = np.quantile(bootstrap_metrics, [design.alpha / 2, 1 - design.alpha / 2]) # слева и справа отрезаем по альфа/2 процентов массы\n",
    "            ci = [left, right]\n",
    "            if left < 0 < right:\n",
    "                pvalue = 1\n",
    "            else:\n",
    "                pvalue = 0\n",
    "\n",
    "        if design.bootstrap_ci_type == 'pivotal':\n",
    "\n",
    "            left, right = 2 * pe_metric - np.quantile(bootstrap_metrics, [1 - design.alpha / 2, design.alpha / 2]) # чтобы получить правую границу, вычитается левая граница персентильного ДИ; левую границу - вычитается правая граница перцентильного ДИ\n",
    "            ci = [left, right]\n",
    "            if left < 0 < right:\n",
    "                pvalue = 1\n",
    "            else:\n",
    "                pvalue = 0\n",
    "        \n",
    "        return ci, pvalue\n",
    "\n",
    "    def get_pvalue(self, metrics_a_group, metrics_b_group, design):\n",
    "        \"\"\"Применяет статтест, возвращает pvalue.\n",
    "        \n",
    "        :param metrics_a_group (np.array): массив значений метрик группы A\n",
    "        :param metrics_a_group (np.array): массив значений метрик группы B\n",
    "        :param design (Design): объект с данными, описывающий параметры эксперимента\n",
    "        :return (float): значение p-value\n",
    "        \"\"\"\n",
    "        if design.statistical_test == 'ttest':\n",
    "            _, pvalue = stats.ttest_ind(metrics_a_group, metrics_b_group)\n",
    "            return pvalue\n",
    "        elif design.statistical_test == 'bootstrap':\n",
    "            bootstrap_metrics, pe_metric = self._generate_bootstrap_metrics(metrics_a_group, metrics_b_group, design)\n",
    "            _, pvalue = self._run_bootstrap(bootstrap_metrics, pe_metric, design)\n",
    "        else:\n",
    "            raise ValueError('Неверный design.statistical_test')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bootstrap_metrics = np.arange(-490, 510)\n",
    "    pe_metric = 5.\n",
    "    design = Design(\n",
    "        statistical_test='bootstrap',\n",
    "        effect=5,\n",
    "        bootstrap_ci_type='normal',\n",
    "        bootstrap_agg_func='mean'\n",
    "    )\n",
    "    ideal_ci = (-560.79258, 570.79258)\n",
    "    ideal_pvalue = 1.\n",
    "\n",
    "    experiments_service = ExperimentsService()\n",
    "    ci, pvalue = experiments_service._run_bootstrap(bootstrap_metrics, pe_metric, design)\n",
    "    np.testing.assert_almost_equal(ideal_ci, ci, decimal=4, err_msg='Неверный доверительный интервал')\n",
    "    assert ideal_pvalue == pvalue, 'Неверный pvalue'\n",
    "    print('simple test passed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
